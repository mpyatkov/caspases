#+TITLE:     Cleavage site searching pipeline
#+AUTHOR:    Max Pyatkov

This document provides some notes about how I obtain tables and create figures for caspase cleavage sites research

#+EMAIL:     test@test.com

#+DESCRIPTION: This document catalogs a set of tips and tricks for composing documents in Org mode.

#+DESCRIPTION: This document catalogs a set of scripts which allow to everyone reproduce this research

#+KEYWORDS:  caspases, n-rule, cleavage sites, apoptosis
#+LANGUAGE:  en
#+OPTIONS:   H:4
#+OPTIONS:   num:nil
#+OPTIONS:   toc:2
#+OPTIONS:   p:t

* Preparing databases and software
** Software

   Almost all information was obtained from this [[   https://bioinf.shenwei.me/taxonkit/tutorial/#making-nr-blastdb-for-specific-taxids][source]]
   
   Main software which I used:
   - [[https://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/ncbi-blast-2.9.0+-x64-linux.tar.gz][NCBI BLAST+]]
   - [[https://github.com/shenwei356/csvtk/releases/download/v0.18.2/csvtk_linux_amd64.tar.gz][CSVTK]]
   - [[https://github.com/shenwei356/seqkit/releases/download/v0.10.2/seqkit_linux_amd64.tar.gz][SEQKIT]]
   - pigz was installed using apt
   - all soft have links in ~/bin

** Download and prepare NR database, obtain subset of Vertebrates
  - Download last NR (non-redundant) database (not in one FASTA file, because headers don't presented very well in FASTA)

#+BEGIN_SRC shell
  wget -c 'https://ftp.ncbi.nlm.nih.gov/blast/db/v5/nr_v5.*.tar.gz'
#+END_SRC

  - Unpack all files to big prepared nr database

#+BEGIN_SRC shell
  cat nr.*.tar.gz | tar -zxvi -f - -C .
#+END_SRC

  - Extracting vertebrates subset
  Note. Actually you can use taxonkit to extract taxids for example as follows:

#+BEGIN_SRC shell
  mkdir -p ~/.taxonkit

  # download taxdump
  wget -c ftp://ftp.ncbi.nih.gov/pub/taxonomy/taxdump.tar.gz
  tar -zxvf taxdump.tar.gz
  ln -s `realpath ./taxdump/names.dmp` ~/.taxonkit/names.dmp
  ln -s `realpath ./taxdump/nodes.dmp` ~/.taxonkit/nodes.dmp
  ln -s `realpath ./taxdump/delnodes.dmp` ~/.taxonkit/delnodes.dmp
  taxonkit list --ids 7742 --indent "" > 7742.txt
#+END_SRC

  But I used [[https://www.ncbi.nlm.nih.gov/books/NBK179288/][entrez]] which in my case is slightly faster:

#+BEGIN_SRC shell
  # install entrez for get_species_taxids.sh
  # install path: $HOME/edirect

  sh -c "$(wget -q ftp://ftp.ncbi.nlm.nih.gov/entrez/entrezdirect/install-edirect.sh -O -)"

  cd ~
  /bin/bash perl -MNet::FTP -e '$ftp = new Net::FTP("ftp.ncbi.nlm.nih.gov", Passive => 1); $ftp->login; $ftp->binary; $ftp->get("/entrez/entrezdirect/edirect.tar.gz");'
  gunzip -c edirect.tar.gz | tar xf -
  rm edirect.tar.gz
  builtin exit
  export PATH=$PATH:$HOME/edirect
  ./edirect/setup.sh
#+END_SRC

  - According to this [[https://ftp.ncbi.nlm.nih.gov/blast/db/v5/blastdbv5.pdf][manual]] I extract subset of vertebrates (id: 7742)
  #+BEGIN_SRC shell
  
  # obtain id of vertebrates
  # get_species_taxids.sh -n Vertebrates
  
  # obtain all taxids for species which are vertebrates
  get_species_taxids.sh -t 7742 > 7742.txid

  #+END_SRC  

  - Convert prepared database to FASTA subset
  #+BEGIN_SRC shell
  
  # strange step, converting nr to fasta. Why do not use FASTA from NCBI ftp? 
  # Well, main reason - more correct headers for sequences inside
  blastdbcmd -db nr_v5 -dbtype prot -entry all -outfmt "%f" -out - | pigz -c > nr.fa.gz
  
  ## download and extract accession numbers which associated with vertebrates
  wget -c ftp://ftp.ncbi.nih.gov/pub/taxonomy/accession2taxid/prot.accession2taxid.gz
  pigz -dc prot.accession2taxid.gz \
      | csvtk grep -t -f taxid -P 7742.txids \
      | csvtk cut -t -f accession.version \
      | sed 1d \
  > 7742.acc
    
  #+END_SRC
  
  - Split FASTA headers to form as one organism - one sequence
    (header[org1][org2]seq ==> header[org1]seq header[org2]seq)
  #+BEGIN_SRC shell
  cat <(echo) <(pigz -dc nr.fa.gz) \
      | perl -e 'BEGIN{ $/ = "\n>"; <>; } while(<>){s/>$//;  $i = index $_, "\n"; $h = substr $_, 0, $i; $s = substr $_, $i+1; if ($h !~ />/) { print ">$_"; next; }; $h = ">$h"; while($h =~ />([^ ]+ .+?) ?(?=>|$)/g){ $h1 = $1; $h1 =~ s/^\W+//; print ">$h1\n$s";} } ' \
      | seqkit grep --delete-matched -f 7742.acc -o nr.7742.fa.gz

  #+END_SRC

  - Create final BLAST db which contains only vertebrates
  #+BEGIN_SRC shell
  pigz -dc nr.7742.fa.gz > nr.7742.fa
  makeblastdb -parse_seqids -in nr.7742.fa -dbtype prot -out nr.7742 -max_file_sz 3000000000
  rm nr.7742.fa
  #+END_SRC
  
  On this step we have prepared BLAST DB which contains only Verterbrates and we can check it:

  #+BEGIN_SRC shell
  # test.sites contains some FASTA sequnces
  export BLASTDB=`pwd`
  time blastp -db nr.7742 -query ./test.sites -outfmt "6 qaccver saccver stitle evalue score pident qseq sseq" -out test10-1.tsv -num_alignments 8000 -num_threads 8 -evalue 1e-16
  #+END_SRC

** Processing part 
   - Note: I heavily used the [[https://www.tidyverse.org/][Tidyverse]] libraries in this study!

   - *$FASTAFILE* - file obtained from TABLE## using script *000-extractPep.R*

   #+BEGIN_SRC shell
   Rscript --vanilla 000-extractPep.R TABLE##
   ## output file name will be in form run[current_date]_1
   #+END_SRC
   
   - Extract all potential orthologs for vertebrates 
   #+BEGIN_SRC shell 
     FASTAFILE=$1
     export BLASTDB=`pwd`
     
     blastp -db nr.7742 -query $FASTAFILE -outfmt "6 qaccver saccver stitle evalue score pident qseq sseq" -out $FASTAFILE.tsv -num_alignments 8000 -num_threads 8 -evalue 1e-16
     #+END_SRC

   - Filtering table FASTAFILE.tsv, removing duplicates
     
     #+BEGIN_SRC shell
     Rscript --vanilla 00-remote-getshort.R $FASTAFILE.tsv
     # output: FASTAFILE_TABLE_UNIQ_ORGS.csv  -- list of unique organisms
     # output: run280819_1_SHORT.csv.gz       -- cleaned FASTAFILE.tsv table 
     #+END_SRC

   - The number of sequences associated with each organism in NR BLAST database (proteom representativeness)

#+BEGIN_SRC shell
  ## grep -Po '(?<=\[).*(?=\]$)' -- extract  ex. [Homo sapiens]$
  ## grep -E -v "\.|\[|\]|\,|=|-|\(|\/"  -- parse garbage
  ## sed -e 's/^ *//;s/ /,/' -- remove spaces which used uniq
  ## grep -f $FASTAFILE_TABLE_UNIQ_ORGS.csv -- get organisms from file

  cat nr.7742.fa | grep ">" | grep -Po '(?<=\[).*(?=\]$)' \
      | cut -d" " -f1,2 | sort | uniq -c | sort -n \
      | grep -E -v "\.|\[|\]|\,|=|-|\(|\/"  | sed -e 's/^ *//;s/ /,/' \
      | grep -f "$FASTAFILE"_TABLE_UNIQ_ORGS.csv > "$FASTAFILE"_TABLE_ORG_PROT_COUNT.csv
#+END_SRC
   - Lineages for each organims was mainly obtained using Taxonkit, but because classification missing particular Classes, Orders, etc. I fill the empty values using other online servers (Wikipedia, ebi.uk, etc).
#+BEGIN_SRC shell
  cat "$FASTAFILE"_TABLE_UNIQ_ORGS.csv | taxonkit name2taxid -j 8 | cut -f 2 | taxonkit lineage -j 8| taxonkit reformat -f "{c};{o};{f};{g};{s}" --miss-rank-repl "__" | cut -f 3 > "$FASTAFILE"_TABLE_SHORT_LINEAGES_TAXONKIT.tsv

#+END_SRC

  - As output of server part we need take 3 tables:
    - $FASTAFILE_SHORT.csv.gz - "short" table contains filter version of big table (run######_1.tsv)
    - $FASTAFILE_TABLE_ORG_PROT_COUNT.csv - table contains count of proteins for each organism
    - $FASTAFILE_TABLE_UNIQ_ORGS.csv - table contains information about uniq organism, this table required only on previous step and can be obtained from "short" in the future.


